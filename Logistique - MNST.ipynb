{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cb845d2d7328>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodules\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmethods\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_methods\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'methods'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import modules as mdl\n",
    "import losses as ls\n",
    "import methods as mtd\n",
    "import logistique_methods as mtd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeu de donn√©es : MINIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## une fois le dataset telecharge, mettre download=False !\n",
    "## Pour le test, train = False\n",
    "## transform permet de faire un preprocessing des donnees (ici ?)\n",
    "\n",
    "#Parameters\n",
    "batch_size=60000\n",
    "\n",
    "\n",
    "#Load data\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('./data', train=True, download=True, \n",
    "                                                          transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                                                                        transforms.Normalize((0.1307,),\n",
    "                                                                                                             (0.3081,))])), \n",
    "                                           batch_size=batch_size, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_digits=10\n",
    "\n",
    "y_onehot = torch.FloatTensor(batch_size, nb_digits) \n",
    "\n",
    "for i,(data,target) in enumerate(train_loader):\n",
    "    #print(i,data.size(),data.type(),target.size(),\n",
    "    #   target.type())\n",
    "    # do something...\n",
    "    X = data\n",
    "    print(X.shape)\n",
    "\n",
    "    print(target.view(-1,1))\n",
    "    ## Encoding des labels en onehot\n",
    "    y_onehot.zero_()\n",
    "    y_onehot.scatter_(1, target.view(-1,1), 1)\n",
    "\n",
    "    print(y_onehot.shape)\n",
    "    break\n",
    "\n",
    "#Shape data\n",
    "X = X.reshape(batch_size,28*28)\n",
    "Y = y_onehot\n",
    "X = torch.cat((X[Y[:,0] == 1], X[Y[:,1] == 1], X[Y[:,2] == 1]))\n",
    "Y = torch.cat((Y[Y[:,0] == 1], Y[Y[:,1] == 1], Y[Y[:,2] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des fonctions d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_g(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_g(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sctochastique model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eps = 3e-1\n",
    "\n",
    "model = mdl.ModuleLinear(len(X[0]), nb_digits)\n",
    "fa = mdl.ActivationFunction(sigmoid, sigmoid_g)\n",
    "\n",
    "c = mtd.stochastique(X, Y, model, fa, ls.MSE(), epsilon=3e-1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(c)), c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eps = 1000000\n",
    "\n",
    "model = ModuleLinear(len(X[0]), nb_digits)\n",
    "fa = ActivationFunction(np.tanh, tanh_g)\n",
    "\n",
    "c = stochastique(X, Y, model, fa, MSE(), epsilon=1000000)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(c)), c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eps= 1e-1\n",
    "\n",
    "model = ModuleLinear(len(X[0]), nb_digits)\n",
    "fa = ActivationFunction(sigmoid, sigmoid_g)\n",
    "\n",
    "c = batch(X, Y, model, fa, MSE(), epsilon=1e-1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(c)), c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mdl.ModuleLinear(len(X[0]), 10)\n",
    "fa = mdl.ActivationFunction(sigmoid, sigmoid_g)\n",
    "\n",
    "c = mtd.batch(X, Y, model, fa, ls.MSE(), epsilon=1e-1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(c)), c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mdl.ModuleLinear(len(X[0]), 10)\n",
    "fa = mdl.ActivationFunction(sigmoid, sigmoid_g)\n",
    "\n",
    "c = mtd.mini_batch(X, Y, model, fa, ls.MSE(), epsilon=1e-1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(c)), c)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
